import openai
from typing import Dict, Any, Optional
import streamlit as st
from config.config import (
    OPENAI_API_KEY, OPENAI_MODEL, DEFAULT_TEMPERATURE, MAX_TOKENS,
    get_llm, get_embeddings, get_langfuse,
    AOAI_API_KEY, AOAI_ENDPOINT, AOAI_DEPLOY_GPT4O
)

class LLMClient:
    """LLM ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ - OpenAI APIÏôÄ Azure OpenAI ÌÜµÏã†"""
    
    def __init__(self):
        self.client = None
        self.azure_llm = None
        self.langfuse = None
        self._initialize_client()
    
    def _initialize_client(self):
        """LLM ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî"""
        try:
            # Azure OpenAI Ïö∞ÏÑ† ÏãúÎèÑ
            if all([AOAI_API_KEY, AOAI_ENDPOINT, AOAI_DEPLOY_GPT4O]):
                self.azure_llm = get_llm()
                if self.azure_llm:
                    st.success("‚úÖ Azure OpenAI Ïó∞Í≤∞ ÏÑ±Í≥µ!")
                    return
            
            # OpenAI API ÏãúÎèÑ
            if OPENAI_API_KEY and OPENAI_API_KEY != "your_openai_api_key_here":
                self.client = openai.OpenAI(api_key=OPENAI_API_KEY)
                st.success("‚úÖ OpenAI API Ïó∞Í≤∞ ÏÑ±Í≥µ!")
                return
            
            # Langfuse Ï¥àÍ∏∞Ìôî
            self.langfuse = get_langfuse()
            if self.langfuse:
                st.info("üìä Langfuse Ïó∞Í≤∞Îê®")
            
            # API ÌÇ§Í∞Ä ÏóÜÎäî Í≤ΩÏö∞
            if not self.azure_llm and not self.client:
                st.warning("‚ö†Ô∏è OpenAI API ÌÇ§Í∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
                st.info("üí° `.env` ÌååÏùºÏóê `OPENAI_API_KEY` ÎòêÎäî Azure OpenAI ÏÑ§Ï†ïÏùÑ Ï∂îÍ∞ÄÌï¥Ï£ºÏÑ∏Ïöî.")
                st.info("üí° API ÌÇ§Í∞Ä ÏóÜÏñ¥ÎèÑ UIÎäî Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏûëÎèôÌïòÏßÄÎßå, AI Í∏∞Îä•ÏùÄ ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§.")
                
        except Exception as e:
            st.error(f"‚ùå LLM ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {str(e)}")
            st.info("üí° API ÌÇ§Î•º ÌôïÏù∏ÌïòÍ≥† Îã§Ïãú ÏãúÎèÑÌï¥Ï£ºÏÑ∏Ïöî.")
    
    def generate_travel_plan(self, prompt: str) -> Optional[str]:
        """Ïó¨Ìñâ Í≥ÑÌöç ÏÉùÏÑ±"""
        
        if not self._is_available():
            st.error("‚ùå LLMÏù¥ Ïó∞Í≤∞ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            st.info("üí° `.env` ÌååÏùºÏóê Ïú†Ìö®Ìïú API ÌÇ§Î•º ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî.")
            return None
        
        try:
            with st.spinner("ü§ñ AIÍ∞Ä Ïó¨Ìñâ Í≥ÑÌöçÏùÑ ÏÉùÏÑ±ÌïòÍ≥† ÏûàÏäµÎãàÎã§..."):
                if self.azure_llm:
                    # Azure OpenAI ÏÇ¨Ïö©
                    response = self.azure_llm.invoke(prompt)
                    return response.content
                else:
                    # OpenAI API ÏÇ¨Ïö©
                    response = self.client.chat.completions.create(
                        model=OPENAI_MODEL,
                        messages=[
                            {
                                "role": "system",
                                "content": "ÎãπÏã†ÏùÄ Ï†ÑÎ¨∏ Ïó¨Ìñâ ÌîåÎûòÎÑàÏûÖÎãàÎã§. ÏÇ¨Ïö©ÏûêÏùò ÏöîÍµ¨ÏÇ¨Ìï≠Ïóê ÎßûÎäî ÏÉÅÏÑ∏ÌïòÍ≥† Ïã§Ïö©Ï†ÅÏù∏ Ïó¨Ìñâ Í≥ÑÌöçÏùÑ Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî."
                            },
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        temperature=DEFAULT_TEMPERATURE,
                        max_tokens=MAX_TOKENS
                    )
                    return response.choices[0].message.content
                
        except Exception as e:
            st.error(f"‚ùå Ïó¨Ìñâ Í≥ÑÌöç ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
            return None
    
    def generate_alternative_plan(self, base_prompt: str, alternative_type: str) -> Optional[str]:
        """ÎåÄÏïà Ïó¨Ìñâ Í≥ÑÌöç ÏÉùÏÑ±"""
        
        if not self._is_available():
            st.error("‚ùå LLMÏù¥ Ïó∞Í≤∞ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            return None
        
        try:
            with st.spinner(f"üîÑ {alternative_type} Ïä§ÌÉÄÏùºÏùò ÎåÄÏïà Í≥ÑÌöçÏùÑ ÏÉùÏÑ±ÌïòÍ≥† ÏûàÏäµÎãàÎã§..."):
                if self.azure_llm:
                    # Azure OpenAI ÏÇ¨Ïö©
                    response = self.azure_llm.invoke(base_prompt)
                    return response.content
                else:
                    # OpenAI API ÏÇ¨Ïö©
                    response = self.client.chat.completions.create(
                        model=OPENAI_MODEL,
                        messages=[
                            {
                                "role": "system",
                                "content": "ÎãπÏã†ÏùÄ Ï†ÑÎ¨∏ Ïó¨Ìñâ ÌîåÎûòÎÑàÏûÖÎãàÎã§. Í∏∞Ï°¥ Í≥ÑÌöçÏùÑ Î∞îÌÉïÏúºÎ°ú Îã§ÏñëÌïú Ïä§ÌÉÄÏùºÏùò ÎåÄÏïàÏùÑ Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî."
                            },
                            {
                                "role": "user",
                                "content": base_prompt
                            }
                        ],
                        temperature=DEFAULT_TEMPERATURE,
                        max_tokens=MAX_TOKENS
                    )
                    return response.choices[0].message.content
                
        except Exception as e:
            st.error(f"‚ùå ÎåÄÏïà Í≥ÑÌöç ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
            return None
    
    def get_weather_info(self, destination: str, duration: int) -> Optional[str]:
        """ÎÇ†Ïî® Ï†ïÎ≥¥ ÏöîÏ≤≠"""
        
        if not self._is_available():
            st.error("‚ùå LLMÏù¥ Ïó∞Í≤∞ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            return None
        
        try:
            with st.spinner("üå§Ô∏è ÎÇ†Ïî® Ï†ïÎ≥¥Î•º Ï°∞ÌöåÌïòÍ≥† ÏûàÏäµÎãàÎã§..."):
                weather_prompt = f"{destination}Ïùò {duration}ÏùºÍ∞Ñ Ïó¨ÌñâÏóê ÎåÄÌïú ÎÇ†Ïî® Ï†ïÎ≥¥ÏôÄ Ï§ÄÎπÑÏÇ¨Ìï≠ÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî."
                
                if self.azure_llm:
                    # Azure OpenAI ÏÇ¨Ïö©
                    response = self.azure_llm.invoke(weather_prompt)
                    return response.content
                else:
                    # OpenAI API ÏÇ¨Ïö©
                    response = self.client.chat.completions.create(
                        model=OPENAI_MODEL,
                        messages=[
                            {
                                "role": "system",
                                "content": "ÎãπÏã†ÏùÄ Ïó¨Ìñâ ÎÇ†Ïî® Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Î™©Ï†ÅÏßÄÏùò ÎÇ†Ïî® Ï†ïÎ≥¥ÏôÄ Ïó¨Ìñâ Ï§ÄÎπÑÏÇ¨Ìï≠ÏùÑ Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî."
                            },
                            {
                                "role": "user",
                                "content": weather_prompt
                            }
                        ],
                        temperature=0.5,
                        max_tokens=1000
                    )
                    return response.choices[0].message.content
                
        except Exception as e:
            st.error(f"‚ùå ÎÇ†Ïî® Ï†ïÎ≥¥ Ï°∞Ìöå Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
            return None
    
    def get_local_tips(self, destination: str) -> Optional[str]:
        """ÌòÑÏßÄÏù∏ ÌåÅ ÏöîÏ≤≠"""
        
        if not self._is_available():
            st.error("‚ùå LLMÏù¥ Ïó∞Í≤∞ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            return None
        
        try:
            with st.spinner("üè† ÌòÑÏßÄÏù∏ ÌåÅÏùÑ ÏàòÏßëÌïòÍ≥† ÏûàÏäµÎãàÎã§..."):
                tips_prompt = f"{destination}Ïóê ÎåÄÌïú ÌòÑÏßÄÏù∏Îßå ÏïÑÎäî ÌåÅÍ≥º Ï†ïÎ≥¥Î•º ÏïåÎ†§Ï£ºÏÑ∏Ïöî."
                
                if self.azure_llm:
                    # Azure OpenAI ÏÇ¨Ïö©
                    response = self.azure_llm.invoke(tips_prompt)
                    return response.content
                else:
                    # OpenAI API ÏÇ¨Ïö©
                    response = self.client.chat.completions.create(
                        model=OPENAI_MODEL,
                        messages=[
                            {
                                "role": "system",
                                "content": "ÎãπÏã†ÏùÄ ÌòÑÏßÄ Ïó¨Ìñâ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Í¥ÄÍ¥ëÍ∞ùÏù¥ Î™®Î•¥Îäî Ïà®Í≤®ÏßÑ Ï†ïÎ≥¥ÏôÄ ÌåÅÏùÑ Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî."
                            },
                            {
                                "role": "user",
                                "content": tips_prompt
                            }
                        ],
                        temperature=0.7,
                        max_tokens=1000
                    )
                    return response.choices[0].message.content
                
        except Exception as e:
            st.error(f"‚ùå ÌòÑÏßÄÏù∏ ÌåÅ ÏàòÏßë Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
            return None
    
    def _is_available(self) -> bool:
        """LLM ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏"""
        return self.azure_llm is not None or self.client is not None
    
    def is_available(self) -> bool:
        """LLM ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏ (Í∏∞Ï°¥ Ìò∏ÌôòÏÑ±)"""
        return self._is_available()
    
    def get_api_status(self) -> Dict[str, Any]:
        """API ÏÉÅÌÉú Ï†ïÎ≥¥ Î∞òÌôò"""
        return {
            "connected": self._is_available(),
            "azure_connected": self.azure_llm is not None,
            "openai_connected": self.client is not None,
            "langfuse_connected": self.langfuse is not None,
            "azure_api_key_set": bool(AOAI_API_KEY and AOAI_API_KEY != "your_azure_openai_api_key_here"),
            "openai_api_key_set": bool(OPENAI_API_KEY and OPENAI_API_KEY != "your_openai_api_key_here"),
            "model": "Azure OpenAI" if self.azure_llm else OPENAI_MODEL,
            "temperature": DEFAULT_TEMPERATURE,
            "max_tokens": MAX_TOKENS
        } 